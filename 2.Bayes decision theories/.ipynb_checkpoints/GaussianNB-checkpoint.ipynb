{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TOC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原文代码作者：https://github.com/wzyonggege/statistical-learning-method,  [K最临近](https://www.cnblogs.com/21207-iHome/p/6084670.html)\n",
    "\n",
    "中文注释制作：机器学习初学者(微信公众号：ID:ai-start-com)\n",
    "\n",
    "配置环境：python 3.6\n",
    "\n",
    "代码全部测试通过。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4章 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于贝叶斯定理与特征条件独立假设的分类方法。\n",
    "\n",
    "模型：\n",
    "\n",
    "- 高斯模型\n",
    "- 多项式模型\n",
    "- 伯努利模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
    "\n",
    "## GaussianNB 高斯朴素贝叶斯\n",
    "\n",
    "特征的可能性被假设为高斯\n",
    "\n",
    "概率密度函数：\n",
    "$$P(x_i | y_k)=\\frac{1}{\\sqrt{2\\pi\\sigma^2_{yk}}}exp(-\\frac{(x_i-\\mu_{yk})^2}{2\\sigma^2_{yk}})$$\n",
    "\n",
    "数学期望(mean)：$\\mu$，方差：$\\sigma^2=\\frac{\\sum(X-\\mu)^2}{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "算法的思路：\n",
    "1. 由于在朴素贝叶斯的假设中，每个特征都是独立分布且符合高斯分布的，因而$p(y^i|x)=arg\\,\\max_{c_k}(p(y^i=c_k)\\prod_{i=j}^{p} p(x_j|y^i=c_k))$,所以求出每个特征分布的参数即可\n",
    "2. 因为特征独立分布且符合高斯分布，因此可根据特征的均值求出$\\mu$,根据方差求出$\\sigma^{2}$,所谓的训练过程也就是求这两个数的过程\n",
    "3. 在训练得到每个特征概率密度后，也就容易得到$p(y^i|x)$，然后就得到该样本的类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程中遇到的知识点\n",
    "\n",
    "### 首先是算法的实现问题\n",
    "高斯分布的一个重要思想是利用贝叶斯公式进行分类预测，本质上是一个生成模型。\n",
    "\n",
    "另外还有两大假设：\n",
    "* 样本和特征之间都互相独立\n",
    "* 特征分布为高斯分布\n",
    "\n",
    "### 还有就是Python的一些重要语法\n",
    "* lamada表达式```f(x) for x in X```用于方便生成\n",
    "for example:\n",
    "```\n",
    "X = [1,2,3]\n",
    "y = list(2*x for x in X)\n",
    "print(y)\n",
    "```\n",
    "* zip()函数的使用\n",
    "zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。\n",
    "如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同，利用 * 号操作符，可以将元组解压为列表。\n",
    "```\n",
    ">>>a = [1,2,3]\n",
    ">>> b = [4,5,6]\n",
    ">>> c = [4,5,6,7,8]\n",
    ">>> zipped = zip(a,b)     # 打包为元组的列表\n",
    "[(1,4),(2,5),(3,6)]\n",
    ">>> zip(a,c)              # 元素个数与最短的列表一致\n",
    "[(1,4),(2,5),(3,6)]\n",
    ">>> zip(*zipped)          # 与 zip 相反，*zipped 可理解为解压，返回二维矩阵式\n",
    "[(1,2,3),(4,5,6)]\n",
    "```\n",
    "注意这一句`summaries = [(self.mean(i), self.stdev(i)) for i in zip(*train_data)]`\n",
    "* sorted()函数的使用sorted(imput,key,reverse)\n",
    "```\n",
    "print(sorted([[2,3,1,5,3,7,2],[2,3,1,5,3,7,1],[2,3,1,5,3,7,3]],key=lambda x: x[-1],reverse=True))#\n",
    "```\n",
    "key参数默认为none，表示直接对数进行比较，在这里为`key=lambda x: x[-1]`表示依据元素的最后一个数进行排序。假如为`key=1/x`，那么按照x的倒数进行排序\n",
    "\n",
    "reverse为True是从高到低\n",
    "* 从其他数据类型生成列表\n",
    "```\n",
    "list(set(y))\n",
    "list(range(number))\n",
    "```\n",
    "* 字典的使用\n",
    "学会字典的建立、添加、检索等常规操作，更要懂得什么时候使用这些方法。[链接](https://www.runoob.com/python/python-dictionary.html)\n",
    "\n",
    "例如本程序中的：\n",
    "```\n",
    "data = {label:[] for label in labels}\n",
    "for f, label in zip(X, y):\n",
    "    data[label].append(f)#给字典添加元素\n",
    "    \n",
    "self.model = {label: self.summarize(value) for label, value in data.items()}#字典的索引\n",
    "```\n",
    "* 会使用math函数库\n",
    "for example：\n",
    "```\n",
    "math.aqrt()\n",
    "math.sum()\n",
    "```\n",
    "* sklearn模型划分模块`from sklearn.model_selection import train_test_split`的使用\n",
    "* 迭代器的使用\n",
    "* 长难句分析\n",
    "```\n",
    "label = sorted(self.calculate_probabilities(X_test).items(), key=lambda x: x[-1])[-1][0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB#高斯朴素贝叶斯算法\n",
    "from sklearn.decomposition import PCA#主成分分析\n",
    "\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    # 数学期望\n",
    "    @staticmethod\n",
    "    def mean(X):\n",
    "        return sum(X) / float(len(X))\n",
    "\n",
    "    # 标准差（方差）\n",
    "    def stdev(self, X):\n",
    "        avg = self.mean(X)\n",
    "        return math.sqrt(sum([pow(x-avg, 2) for x in X]) / float(len(X)))\n",
    "\n",
    "    # 概率密度函数\n",
    "    def gaussian_probability(self, x, mean, stdev):\n",
    "        exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "        return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "    # 处理X_train\n",
    "    def summarize(self, train_data):\n",
    "        summaries = [(self.mean(i), self.stdev(i)) for i in zip(*train_data)]#https://www.runoob.com/python/python-func-zip.html有一个转置的作用\n",
    "        ##zip(*train_data)为p*N\n",
    "        \n",
    "        return summaries#summaries为p*2的一个矩阵\n",
    "\n",
    "    # 分类别求出数学期望和标准差\n",
    "    def fit(self, X, y):\n",
    "        labels = list(set(y))#标签的列表\n",
    "        data = {label:[] for label in labels}#{0.0: [], 1.0: []}\n",
    "        for f, label in zip(X, y):\n",
    "            data[label].append(f)#print(data)#形成一个字典，根据标签将训练样本进行分类\n",
    "        \n",
    "        self.model = {label: self.summarize(value) for label, value in data.items()}#每个特征的平均值和标准差，知道这两个，所有模型也就确定了\n",
    "        print(self.model)\n",
    "        return 'gaussianNB train done!'\n",
    "\n",
    "    # 计算概率\n",
    "    def calculate_probabilities(self, input_data):\n",
    "        # summaries:{0.0: [(5.0, 0.37),(3.42, 0.40)], 1.0: [(5.8, 0.449),(2.7, 0.27)]}\n",
    "        # input_data:[1.1, 2.2]\n",
    "        probabilities = {}\n",
    "        for label, value in self.model.items():\n",
    "            probabilities[label] = 1#先验概率，由于假定每个出现的结果都一样，所以在这里均设为1\n",
    "            for i in range(len(value)):#特征个数\n",
    "                mean, stdev = value[i]\n",
    "                probabilities[label] *= self.gaussian_probability(input_data[i], mean, stdev)#这句是计算核心，计算分别为每个标签的可能性\n",
    "        return probabilities#输出各个结果的可能性，生成一个字典\n",
    "\n",
    "    # 类别\n",
    "    def predict(self, X_test):\n",
    "        # {0.0: 2.9680340789325763e-27, 1.0: 3.5749783019849535e-26}\n",
    "        label = sorted(self.calculate_probabilities(X_test).items(), key=lambda x: x[-1])[-1][0]#sorted是一个排序函数,key参数表示通过对x的最后一个数进行比较排序\n",
    "        return label\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right = 0\n",
    "        for X, y in zip(X_test, y_test):\n",
    "            label = self.predict(X)\n",
    "            if label == y:\n",
    "                right += 1\n",
    "\n",
    "        return right / float(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 4) (30, 4) (70,) (30,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    data = np.array(df.iloc[:100, :])\n",
    "    # print(data)\n",
    "    return data[:,:-1], data[:,-1]\n",
    "\n",
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "model = NaiveBayes()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "scikit-learn实例\n",
    "\n",
    "# sklearn.naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB, MultinomialNB # 伯努利模型和多项式模型\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "clf.predict([[4.4,  3.2,  1.3,  0.2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多变量高斯分布的贝叶斯分类器  \n",
    "\n",
    "概率密度：\n",
    "$$p(x)=N(x|\\mu,\\Sigma)=\\frac1{(2\\pi)^\\frac{p}2}\\frac1{|\\Sigma|^\\frac1{2}}e^{-\\frac1{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)}$$\n",
    "\n",
    "其中$\\mu=\\frac1{N}\\sum_{i=1}^{N}x_i$\n",
    "\n",
    "$ \\Sigma=\\frac1N\\sum_{i=1}^{N}(x_i-\\mu)(x_i-\\mu)^T$\n",
    "\n",
    "整体上的思路与朴素贝叶斯无异，不同之处在于高斯分布的朴素贝叶斯决策是假设各特征之间是互相独立的，而多变量高斯分布没有这样的假设，因此在同样的数据集下多变量高斯分布的贝叶斯分类器效果要好于服从高斯分布的朴素贝叶斯，两者在算法上的差异就在于求$p(x|y)$上，前者求出每个特征的分布，后者求出总体的分布。\n",
    "\n",
    "算法思路：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVGaussion:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    @staticmethod\n",
    "    # mathematical expectation\n",
    "    def mu(X):\n",
    "        return sum(X) / float(len(X))#生成一个p*1的特征均值矩阵\n",
    "\n",
    "    # sigma natrix(p*p)\n",
    "    def sigma(self, train_data,train_mu):\n",
    "        train_data_shape = np.shape(train_data)\n",
    "        sigma = np.zeros((train_data_shape[1],train_data_shape[1]))\n",
    "        for sample in zip(train_data):\n",
    "            dot = sample-train_mu\n",
    "            sigma += np.dot(dot.T,dot)\n",
    "        return sigma/train_data_shape[0]\n",
    "\n",
    "    # 处理X_train\n",
    "    def summarize(self, train_data):#train_data为一个N*p的矩阵\n",
    "        mu = [self.mu(i) for i in zip(*train_data)]#1*P\n",
    "        #muT = np.array(mu).reshape(np.size(mu),1)\n",
    "        sigma = self.sigma(train_data,np.array(mu))\n",
    "        summaries = {'mu':mu,'sigma':sigma}#\n",
    "        return summaries#summaries得到的模型参数应该为一个p*1的mu矩阵和一个p*p的大sigma矩阵\n",
    "\n",
    "    # 分类别求出数学期望和标准差\n",
    "    def train(self, X, y):\n",
    "        labels = list(set(y))\n",
    "        data = {label:[] for label in labels}#\n",
    "        for f, label in zip(X, y):\n",
    "            data[label].append(f)\n",
    "        self.model = {label: self.summarize(value) for label, value in data.items()}\n",
    "#         print(self.model)\n",
    "#         for label, value in self.model.items():\n",
    "#             mu,sigma = value['mu'],value['sigma']\n",
    "#             print(mu)\n",
    "#             print(sigma)\n",
    "        return self.model\n",
    "\n",
    "    # 计算概率\n",
    "    def calculate_probabilities(self, input_data):\n",
    "        probabilities = {}\n",
    "        p = np.size(input_data)\n",
    "        for label, value in self.model.items():#value是一个字典\n",
    "            mu,sigma = value['mu'],value['sigma']\n",
    "            sign = input_data-mu\n",
    "            exponent = math.exp((-0.5*np.dot(sign,np.dot(np.linalg.inv(sigma),sign.T))))\n",
    "            probabilities[label] = exponent/(((2*math.pi)**(p/2))*(np.linalg.det(sigma)**0.5))\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    # 类别\n",
    "    def predict(self, X_test):\n",
    "        label = list(range(X_test.shape[0]))\n",
    "        for i in range(X_test.shape[0]):\n",
    "            label[i] = sorted(self.calculate_probabilities(X_test[i,:]).items(), key=lambda x: x[-1])[-1][0]\n",
    "        \n",
    "        return label\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right = 0\n",
    "        for X, y in zip(X_test, y_test):\n",
    "            label = self.predict(X)\n",
    "            if label == y:\n",
    "                right += 1\n",
    "\n",
    "        return right / float(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.使用多变量高斯分布贝叶斯决策解决IRIS分类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS:Number of mislabeled points out of a total 75 points : 0, Acc: 100.000000%\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "\n",
    "\n",
    "model = MVGaussion()\n",
    "model.train(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"IRIS:Number of mislabeled points out of a total %d points : %d, Acc: %f%%\"\n",
    "      % (X_test.shape[0], (y_test != y_pred).sum(),100*(y_test == y_pred).sum()/X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 使用多变量高斯分布贝叶斯决策解决手写数字分类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USPS:Number of mislabeled points out of a total 4649 points : 185, Acc: 96.020650%\n"
     ]
    }
   ],
   "source": [
    "digits=fetch_openml(name='USPS',version=2,data_home='E:/scikit_learn_data')\n",
    "X_d=digits.data\n",
    "y_d=digits.target\n",
    "y_u=np.unique(y_d)\n",
    "enc = LabelEncoder()\n",
    "enc.fit(y_d)\n",
    "name=enc.classes_\n",
    "\n",
    "y1=enc.transform(y_d)\n",
    "X_reduced = PCA(n_components=30).fit_transform(X_d)#特征提取\n",
    "\n",
    "X_train_d, X_test_d, y_train_d, y_test_d = train_test_split(X_reduced, y1, test_size=0.5, random_state=1)\n",
    "\n",
    "model_d = MVGaussion()\n",
    "model_d.train(X_train_d, y_train_d)\n",
    "y_pred_d = model_d.predict(X_test_d)\n",
    "\n",
    "print(\"USPS:Number of mislabeled points out of a total %d points : %d, Acc: %f%%\"\n",
    "      %(X_test_d.shape[0], (y_test_d != y_pred_d).sum(),100*(y_test_d == y_pred_d).sum()/X_test_d.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
